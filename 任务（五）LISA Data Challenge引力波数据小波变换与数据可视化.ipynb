{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73bbe1be",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "``C:\\Users\\28919\\\"D:\\BaiduNetdiskDownload\\LDC2_spritz_mbhb1_training_v1.h5\"`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtables\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 打开 HDF5 文件\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tables\u001b[38;5;241m.\u001b[39mopen_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBaiduNetdiskDownload\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLDC2_spritz_mbhb1_training_v1.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# 获取文件中的数据集\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39mdataset_name\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# 读取数据集的内容\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tables\\file.py:294\u001b[0m, in \u001b[0;36mopen_file\u001b[1;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    290\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already opened.  Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose it before reopening in write mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m filename)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# Finally, create the File instance, and return it\u001b[39;00m\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m File(filename, mode, title, root_uep, filters, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tables\\file.py:744\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m    743\u001b[0m \u001b[38;5;66;03m# Now, it is time to initialize the File extension\u001b[39;00m\n\u001b[1;32m--> 744\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_g_new(filename, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;66;03m# Check filters and set PyTables format version for new files.\u001b[39;00m\n\u001b[0;32m    747\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_new\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tables\\hdf5extension.pyx:394\u001b[0m, in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tables\\utils.py:146\u001b[0m, in \u001b[0;36mcheck_file_access\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# The file should be readable.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39maccess(path, os\u001b[38;5;241m.\u001b[39mF_OK):\n\u001b[1;32m--> 146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`` does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`` is not a regular file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: ``C:\\Users\\28919\\\"D:\\BaiduNetdiskDownload\\LDC2_spritz_mbhb1_training_v1.h5\"`` does not exist"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tables\n",
    "# 打开 HDF5 文件\n",
    "with tables.open_file('\"D:\\BaiduNetdiskDownload\\LDC2_spritz_mbhb1_training_v1.h5\"', 'r') as f:\n",
    "    # 获取文件中的数据集\n",
    "    dataset = f.root.dataset_name\n",
    "    \n",
    "    # 读取数据集的内容\n",
    "    data = dataset[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e33c626",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '：' (U+FF1A) (2528445137.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    with h5py.File('LDC2_spritz_mbhb1_training_v1.h5','r') as f：\u001b[0m\n\u001b[1;37m                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character '：' (U+FF1A)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('LDC2_spritz_mbhb1_training_v1.h5','r') as f："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896c968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abb4c9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Python</th>\n",
       "      <th>Math</th>\n",
       "      <th>En</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Python  Math  En\n",
       "A       3     5   8\n",
       "B       1     3   5\n",
       "C       1     0   5\n",
       "D       9     7   6\n",
       "E      12     7   3\n",
       "F       0     4   3\n",
       "H       6     5   5\n",
       "I      12     9  14\n",
       "J       2     4  13\n",
       "K      13    14   1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(data=np.random.randint(0,15,size=(10,3)),\n",
    "                   index=list('ABCDEFHIJK'),#行索引\n",
    "                   columns=['Python','Math','En'])#列索引\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3246efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设你有一个名为 data 的字典，用于创建 DataFrame\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 将 DataFrame 保存为 HDF5 文件\n",
    "df.to_hdf('LDC2_spritz_mbhb1_training_v1.h5', key='abc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e48b3a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vitablesNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading vitables-3.0.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: qtpy>=2.2 in c:\\users\\28919\\anaconda3\\lib\\site-packages (from vitables) (2.4.1)\n",
      "Requirement already satisfied: setuptools>=65.0 in c:\\users\\28919\\anaconda3\\lib\\site-packages (from vitables) (68.2.2)\n",
      "Requirement already satisfied: tables>=3.0 in c:\\users\\28919\\anaconda3\\lib\\site-packages (from vitables) (3.9.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\28919\\anaconda3\\lib\\site-packages (from qtpy>=2.2->vitables) (23.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\28919\\anaconda3\\lib\\site-packages (from tables>=3.0->vitables) (1.26.4)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in c:\\users\\28919\\anaconda3\\lib\\site-packages (from tables>=3.0->vitables) (2.8.7)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\28919\\anaconda3\\lib\\site-packages (from tables>=3.0->vitables) (9.0.0)\n",
      "Downloading vitables-3.0.3-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.0 MB 93.9 kB/s eta 0:00:11\n",
      "    --------------------------------------- 0.0/1.0 MB 93.9 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.0/1.0 MB 151.3 kB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.0/1.0 MB 151.3 kB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.1/1.0 MB 196.9 kB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.1/1.0 MB 196.9 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.1/1.0 MB 201.8 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.1/1.0 MB 201.8 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.1/1.0 MB 201.8 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.1/1.0 MB 179.0 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.1/1.0 MB 179.0 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.1/1.0 MB 218.6 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.1/1.0 MB 218.6 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 0.2/1.0 MB 228.2 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 0.2/1.0 MB 228.2 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.2/1.0 MB 210.2 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.2/1.0 MB 210.2 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.2/1.0 MB 210.2 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.2/1.0 MB 210.2 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.2/1.0 MB 210.2 kB/s eta 0:00:04\n",
      "   --------- ------------------------------ 0.2/1.0 MB 218.5 kB/s eta 0:00:04\n",
      "   --------- ------------------------------ 0.2/1.0 MB 218.5 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.3/1.0 MB 215.6 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 0.3/1.0 MB 215.6 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 0.3/1.0 MB 224.1 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 0.3/1.0 MB 224.1 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 0.3/1.0 MB 224.1 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.3/1.0 MB 221.1 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.3/1.0 MB 221.1 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.3/1.0 MB 228.0 kB/s eta 0:00:03\n",
      "   ------------- -------------------------- 0.3/1.0 MB 228.0 kB/s eta 0:00:03\n",
      "   ------------- -------------------------- 0.3/1.0 MB 218.6 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.3/1.0 MB 218.6 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 0.4/1.0 MB 231.0 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 0.4/1.0 MB 231.0 kB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 0.4/1.0 MB 234.1 kB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 0.4/1.0 MB 234.1 kB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 0.4/1.0 MB 234.1 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 0.5/1.0 MB 238.9 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 0.5/1.0 MB 238.9 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.5/1.0 MB 235.9 kB/s eta 0:00:03\n",
      "   ------------------ --------------------- 0.5/1.0 MB 235.9 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.5/1.0 MB 238.4 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.5/1.0 MB 238.4 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.5/1.0 MB 238.4 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.5/1.0 MB 238.4 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.5/1.0 MB 238.4 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.5/1.0 MB 238.4 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 0.5/1.0 MB 238.4 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.5/1.0 MB 209.9 kB/s eta 0:00:03\n",
      "   -------------------- ------------------- 0.5/1.0 MB 209.9 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 0.6/1.0 MB 219.9 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 0.6/1.0 MB 219.9 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 0.6/1.0 MB 226.4 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 0.6/1.0 MB 226.4 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 0.6/1.0 MB 226.4 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 0.6/1.0 MB 222.3 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 0.6/1.0 MB 228.5 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 0.6/1.0 MB 228.5 kB/s eta 0:00:02\n",
      "   ------------------------- -------------- 0.6/1.0 MB 222.1 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 0.7/1.0 MB 231.5 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 0.7/1.0 MB 231.5 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 0.7/1.0 MB 231.5 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 0.7/1.0 MB 234.3 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 0.7/1.0 MB 238.4 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 0.8/1.0 MB 241.7 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 0.8/1.0 MB 241.0 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 247.4 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 247.4 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 0.8/1.0 MB 248.5 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 0.8/1.0 MB 248.5 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 0.8/1.0 MB 248.5 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 0.8/1.0 MB 248.5 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 0.9/1.0 MB 248.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 0.9/1.0 MB 248.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 0.9/1.0 MB 249.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 0.9/1.0 MB 249.7 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 0.9/1.0 MB 246.1 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.0/1.0 MB 256.1 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.0/1.0 MB 256.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 257.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 257.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 257.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 257.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 250.1 kB/s eta 0:00:00\n",
      "Installing collected packages: vitables\n",
      "Successfully installed vitables-3.0.3\n"
     ]
    }
   ],
   "source": [
    " pip install vitables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c35fd020",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1169311196.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    vitables LDC2_spritz_mbhb1_training_v1.h5\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "vitables LDC2_spritz_mbhb1_training_v1.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dcb41b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clean', 'header', 'instru', 'noisefree', 'obs', 'sky']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "# 打开 HDF5 文件\n",
    "with h5py.File('LDC2_spritz_mbhb1_training_v1.h5', 'r') as GW:\n",
    "    # 获取文件中所有数据集的名称\n",
    "    datasets = list(GW.keys())\n",
    "\n",
    "    print(datasets)\n",
    "\n",
    "# 打开 HDF5 文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e92a20b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid location identifier (invalid location identifier)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 读取 HDF5 文件中的数据集并转换为 DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(GW[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstru/config\u001b[39m\u001b[38;5;124m'\u001b[39m][:])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 使用 head() 函数查看 DataFrame 的前几行数据，默认为前 5 行\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m h5o\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e(name), lapl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lapl)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5o.pyx:190\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid location identifier (invalid location identifier)"
     ]
    }
   ],
   "source": [
    " # 读取 HDF5 文件中的数据集并转换为 DataFrame\n",
    "    df = pd.DataFrame(GW['instru/config'][:])\n",
    "\n",
    "# 使用 head() 函数查看 DataFrame 的前几行数据，默认为前 5 行\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0701c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfb56690",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1563727796.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[62], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    df_GW = pd.read_csvl'./40Gc top.txt', sep='' ', index_col='Number', names=names[2:-2].split(', '), skiprows=1, engine='python\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_GW = pd.read_csvl'./40Gc top.txt', sep='' ', index_col='Number', names=names[2:-2].split(', '), skiprows=1, engine='python\n",
    "df_GW\n",
    "#此代码参考b站老师讲解视频，虽然不一样，他讲的是txt类型转化为hdf5类型，我照猫画虎试了试，失败ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "585a6473",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'File' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m GW\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'File' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "GW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6b097db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 C 中的卷是 Windows-SSD\n",
      " 卷的序列号是 D46A-B63E\n",
      "\n",
      " C:\\Users\\28919 的目录\n",
      "\n",
      "\n",
      " C:\\Users\\28919 的目录\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "找不到文件\n"
     ]
    }
   ],
   "source": [
    "ls -lh *0GC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25f2df44",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (639964720.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[66], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    head file.h5\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "head file.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87dc7ea",
   "metadata": {},
   "source": [
    "*,内心吐槽：尝试了很多办法，也参考了b站的视频，但是没有找到和此类文件数据类型类似的讲解，我尽力了，实在是不知道怎样处理这些数据。（哭）!\n",
    "*成功点：1 在终端输入该指令：vitables LDC2_spritz_mbhb1_training_v1.h5，将hdf5数据可视化。\n",
    "2 掌握了使用pandas库进行简单的命令。\n",
    "*尝试做此题的原因：最近在组会讨论小波变换的机理，理论部分很好懂，可实际处理起来，很复杂，只能说人工智能yyds，虽然我卡在了第一步，更要继续学习。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
